{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment6_MarinaSmirnova.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOBeRZcIL34dbBjr6MVkgUe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"H_ridGY6paVH"},"source":["# Face Recognition.\n","\n","## Implementation steps:\n","\n","1. Obtain a video (youtube-dl)\n","2. Process the video \n","  - detect faces\n","  - compute embeddings\n","  - recognize faces\n","  - prepare a table {PERSON_ID, TIME_INTERVALS, FACE_SAMPLES}\n","  - draw bounding boxes + names\n","3. Record output file \n","\n","## TODO:\n","- submit python code file + link to the output video\n"]},{"cell_type":"markdown","metadata":{"id":"WJ8jJF3bpojt"},"source":["## Used technical stack\n","\n","- **For face detection and recognition** - face_recognition library\n","- **For other video processings** - cv2"]},{"cell_type":"markdown","metadata":{"id":"-wiTZ9wJph6J"},"source":["## MVP specifications\n","\n","1. Accuracy of face detection and recognition has room for improvement, because there are cases of assigning several `PersonId`s to the same person. \n"]},{"cell_type":"markdown","metadata":{"id":"CG2l0id6red-"},"source":["## Acknowledgements\n","- [How to use face_recognition library](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam_faster.py)"]},{"cell_type":"markdown","metadata":{"id":"s-5O9Juf2vGR"},"source":["### A note:\n","for some reason execution of the program in Colab took more than 40 minutes, and I interrupted it."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lVlsBnLPqY7F","executionInfo":{"status":"ok","timestamp":1632924119619,"user_tz":-180,"elapsed":55278,"user":{"displayName":"Marina Smirnova","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15473064881689445612"}},"outputId":"971ab7ed-798b-4a20-f2c3-9260464eded4"},"source":["!pip install youtube-dl\n","!pip install opencv-contrib-python==3.4.2.17\n","!pip install cmake\n","!pip install face_recognition"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting youtube-dl\n","  Downloading youtube_dl-2021.6.6-py2.py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 5.1 MB/s \n","\u001b[?25hInstalling collected packages: youtube-dl\n","Successfully installed youtube-dl-2021.6.6\n","Collecting opencv-contrib-python==3.4.2.17\n","  Downloading opencv_contrib_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (30.6 MB)\n","\u001b[K     |████████████████████████████████| 30.6 MB 25 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python==3.4.2.17) (1.19.5)\n","Installing collected packages: opencv-contrib-python\n","  Attempting uninstall: opencv-contrib-python\n","    Found existing installation: opencv-contrib-python 4.1.2.30\n","    Uninstalling opencv-contrib-python-4.1.2.30:\n","      Successfully uninstalled opencv-contrib-python-4.1.2.30\n","Successfully installed opencv-contrib-python-3.4.2.17\n","Requirement already satisfied: cmake in /usr/local/lib/python3.7/dist-packages (3.12.0)\n","Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Collecting face-recognition-models>=0.3.0\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[K     |████████████████████████████████| 100.1 MB 15 kB/s \n","\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=aeee3163773724547b57fa2e015cbeba6df1ad468ba5266aed25a807f879a897\n","  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face-recognition\n","Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"]}]},{"cell_type":"code","metadata":{"id":"g17BI1MFd99J","executionInfo":{"status":"ok","timestamp":1632924152499,"user_tz":-180,"elapsed":559,"user":{"displayName":"Marina Smirnova","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15473064881689445612"}}},"source":["import youtube_dl\n","import cv2\n","import matplotlib.pyplot as plt\n","import face_recognition\n","import copy"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"LMkX2RUgq08o","executionInfo":{"status":"ok","timestamp":1632924156048,"user_tz":-180,"elapsed":706,"user":{"displayName":"Marina Smirnova","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15473064881689445612"}}},"source":["def print_time_interval(time_start, time_end):\n","    min_start, sec_start = divmod(time_start, 60)\n","    min_end, sec_end = divmod(time_end, 60)\n","    print('[{}:{:.2f} - {}:{:.2f}]'.format(int(min_start), sec_start, int(min_end), sec_end))"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ViIaOrHeq1yx","executionInfo":{"status":"ok","timestamp":1632924156838,"user_tz":-180,"elapsed":2,"user":{"displayName":"Marina Smirnova","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15473064881689445612"}}},"source":["def print_table(table):\n","    for key, value in table.items():\n","        print('\\nPerson ID: {}'.format(key))\n","        print('Time intervals:')\n","        for i in range(len(value['TIME_START'])):\n","            print_time_interval(value['TIME_START'][i], value['TIME_END'][i])\n","        print('Face sample:')\n","        plt.imshow(value['FACE_SAMPLE'])\n","        plt.show()"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"GvP67ZI-q39Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632924159616,"user_tz":-180,"elapsed":1159,"user":{"displayName":"Marina Smirnova","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15473064881689445612"}},"outputId":"ddaf4b85-14e7-492c-ba3d-067fe014d7c1"},"source":["# Download a video\n","ydl_opts = {}\n","with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n","   ydl.download(['https://www.youtube.com/watch?v=gOFt-sz1T2A'])"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[youtube] gOFt-sz1T2A: Downloading webpage\n","[download] YOLO - We Are One ft. Культура Небес (Official Music Video)-gOFt-sz1T2A.webm has already been downloaded and merged\n"]}]},{"cell_type":"code","metadata":{"id":"DfyoW2sEq_3H","executionInfo":{"status":"ok","timestamp":1632924182146,"user_tz":-180,"elapsed":772,"user":{"displayName":"Marina Smirnova","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15473064881689445612"}}},"source":["# Open the video\n","filename = 'YOLO - We Are One ft. Культура Небес (Official Music Video)-gOFt-sz1T2A.webm'\n","cap = cv2.VideoCapture(filename)\n","if not cap.isOpened():\n","    print(\"Error opening video stream or file\")\n","\n","frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps = int(cap.get(cv2.CAP_PROP_FPS))  # 25\n","frame_size = (frame_width, frame_height)  # (3840, 2160)\n","frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","duration = int(frame_count / fps)  # 229.08 sec\n","\n","# Configure output video\n","output_filename = 'video_tracking.mp4'\n","fps = int(cap.get(cv2.CAP_PROP_FPS))\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","output = cv2.VideoWriter(output_filename, fourcc, fps, frame_size)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"WW1v8YsirIBe"},"source":["known_face_encodings = []\n","known_face_names = []\n","\n","face_locations = []\n","face_encodings = []\n","current_face_names = []\n","previous_face_names = []\n","\n","process_this_frame = True\n","personID = 0\n","frames_counter = 0\n","table = {}\n","# PERSON_ID: key in the dictionary\n","# {FACE_ENCODING: string,\n","# TIME_START: list seconds with the beginning of the time interval,\n","# TIME_END: list seconds with the ending of the time interval,\n","# FACE_SAMPLE: img as array\n","# }\n","\n","while cap.isOpened():\n","    success, frame = cap.read()\n","    frames_counter += 1\n","\n","    if success:\n","        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n","        rgb_frame = frame[:, :, ::-1]\n","\n","        if process_this_frame:\n","            # Find all the faces and face encodings in the current frame of video\n","            face_locations = face_recognition.face_locations(rgb_frame)\n","            face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n","\n","            current_face_names = []\n","            for face_encoding in face_encodings:\n","                # See if the face is a match for the known face(s)\n","                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n","                name = ''\n","\n","                # If a match was found in known_face_encodings, just use the first one.\n","                if True in matches:\n","                    first_match_index = matches.index(True)\n","                    name = known_face_names[first_match_index]\n","                else:\n","                    name = \"person\" + str(personID)\n","                    personID += 1\n","                    known_face_names.append(name)\n","                    known_face_encodings.append(face_encoding)\n","                    table[name] = {'FACE_ENCODING': face_encoding}\n","                    table[name]['TIME_START'] = []  # TIME_START\n","                    table[name]['TIME_END'] = []  # TIME_END\n","\n","                current_face_names.append(name)\n","\n","            # Save time intervals\n","            # compare current_face_names and previous_face_names:\n","            # if someone (in current)&(not in previous) -> person appeared\n","            # if someone (not in current)&(in previous) -> person disappeared\n","            new_faces = list(set(current_face_names) - set(previous_face_names))\n","            disappeared_faces = list(set(previous_face_names) - set(current_face_names))\n","            for face_name in new_faces:\n","                table[face_name]['TIME_START'].append(frames_counter / fps)  # append starting time in sec\n","            for face_name in disappeared_faces:\n","                table[face_name]['TIME_END'].append(frames_counter / fps)  # append ending time in sec\n","\n","            previous_face_names = current_face_names\n","\n","        process_this_frame = not process_this_frame\n","\n","        # Draw bounding boxes\n","        for (top, right, bottom, left), name in zip(face_locations,\n","                                                    current_face_names):  # left=x, top=y, right=x+w, bottom=y+h\n","            # Save sample\n","            if 'FACE_SAMPLE' not in table[name]:\n","                table[name]['FACE_SAMPLE'] = copy.deepcopy(frame[top:bottom, left:right])\n","\n","            # Draw a box around the face\n","            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n","\n","            font = cv2.FONT_HERSHEY_DUPLEX\n","            cv2.putText(frame, name, (left + 6, bottom + 30), font, 1.0, (0, 0, 255), 1)\n","\n","        output.write(frame)\n","\n","    else:\n","        break\n","\n","cap.release()\n","output.release()\n","\n","print_table(table)\n","print('The number of people detected and recognized on the video is {}.'.format(len(table.keys())))"],"execution_count":null,"outputs":[]}]}